{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":19843,"sourceType":"datasetVersion","datasetId":14859},{"sourceId":8248567,"sourceType":"datasetVersion","datasetId":4894020}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mennaahmad/datascienceproject-9bf85d-016508-024bff?scriptVersionId=176556284\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-09T02:55:36.442245Z","iopub.execute_input":"2024-05-09T02:55:36.442626Z","iopub.status.idle":"2024-05-09T02:55:36.956916Z","shell.execute_reply.started":"2024-05-09T02:55:36.442596Z","shell.execute_reply":"2024-05-09T02:55:36.955878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#read data that from 2005 to 2014\naccident_data = pd.read_csv('/kaggle/input/uk-accidents-10-years-history-with-many-variables/Accidents0514.csv')\nvehicles_data = pd.read_csv('/kaggle/input/uk-accidents-10-years-history-with-many-variables/Vehicles0514.csv')\ncasualties_data = pd.read_csv('/kaggle/input/uk-accidents-10-years-history-with-many-variables/Casualties0514.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:55:36.95917Z","iopub.execute_input":"2024-05-09T02:55:36.959799Z","iopub.status.idle":"2024-05-09T02:55:58.486998Z","shell.execute_reply.started":"2024-05-09T02:55:36.959754Z","shell.execute_reply":"2024-05-09T02:55:58.486007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accident_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:55:58.488809Z","iopub.execute_input":"2024-05-09T02:55:58.489244Z","iopub.status.idle":"2024-05-09T02:55:58.497211Z","shell.execute_reply.started":"2024-05-09T02:55:58.489203Z","shell.execute_reply":"2024-05-09T02:55:58.496113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accident_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:55:58.500217Z","iopub.execute_input":"2024-05-09T02:55:58.500536Z","iopub.status.idle":"2024-05-09T02:55:58.542292Z","shell.execute_reply.started":"2024-05-09T02:55:58.500509Z","shell.execute_reply":"2024-05-09T02:55:58.541148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vehicles_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:55:58.543895Z","iopub.execute_input":"2024-05-09T02:55:58.544374Z","iopub.status.idle":"2024-05-09T02:55:58.551212Z","shell.execute_reply.started":"2024-05-09T02:55:58.544285Z","shell.execute_reply":"2024-05-09T02:55:58.550055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vehicles_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:55:58.552726Z","iopub.execute_input":"2024-05-09T02:55:58.553576Z","iopub.status.idle":"2024-05-09T02:55:58.579584Z","shell.execute_reply.started":"2024-05-09T02:55:58.553535Z","shell.execute_reply":"2024-05-09T02:55:58.578465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"casualties_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:55:58.581202Z","iopub.execute_input":"2024-05-09T02:55:58.581614Z","iopub.status.idle":"2024-05-09T02:55:58.59178Z","shell.execute_reply.started":"2024-05-09T02:55:58.581577Z","shell.execute_reply":"2024-05-09T02:55:58.590793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"casualties_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:55:58.59322Z","iopub.execute_input":"2024-05-09T02:55:58.593671Z","iopub.status.idle":"2024-05-09T02:55:58.613248Z","shell.execute_reply.started":"2024-05-09T02:55:58.593642Z","shell.execute_reply":"2024-05-09T02:55:58.612135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# accident_data.replace(-1, 'NaN', inplace=True)\n# vehicles_data.replace(-1, 'NaN', inplace=True)\n# casualties_data.replace(-1, 'NaN', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:55:58.614826Z","iopub.execute_input":"2024-05-09T02:55:58.615194Z","iopub.status.idle":"2024-05-09T02:55:58.623428Z","shell.execute_reply.started":"2024-05-09T02:55:58.615164Z","shell.execute_reply":"2024-05-09T02:55:58.622171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge Accidents and Casualties dataframes on 'Accident_Index'\nfinal_data = pd.merge(accident_data, casualties_data, on='Accident_Index')\n# Merge df with Vehicles dataframe on 'Accident_Index'\nfinal_data = pd.merge(final_data, vehicles_data, on='Accident_Index')\n#remove Accidents, Casualties, and Vehicles dataframes\ndel accident_data, casualties_data, vehicles_data","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:55:58.628377Z","iopub.execute_input":"2024-05-09T02:55:58.62881Z","iopub.status.idle":"2024-05-09T02:56:10.904767Z","shell.execute_reply.started":"2024-05-09T02:55:58.628776Z","shell.execute_reply":"2024-05-09T02:56:10.903753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final_data = pd.merge(accident_data, casualties_data, on='Accident_Index', how='left')\n# final_data = pd.merge(final_data, vehicles_data, on='Accident_Index', how='left')","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:10.90611Z","iopub.execute_input":"2024-05-09T02:56:10.906441Z","iopub.status.idle":"2024-05-09T02:56:10.910931Z","shell.execute_reply.started":"2024-05-09T02:56:10.906413Z","shell.execute_reply":"2024-05-09T02:56:10.909916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:10.912195Z","iopub.execute_input":"2024-05-09T02:56:10.912484Z","iopub.status.idle":"2024-05-09T02:56:10.945847Z","shell.execute_reply.started":"2024-05-09T02:56:10.912459Z","shell.execute_reply":"2024-05-09T02:56:10.944046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(final_data.columns)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:10.947409Z","iopub.execute_input":"2024-05-09T02:56:10.947893Z","iopub.status.idle":"2024-05-09T02:56:10.956925Z","shell.execute_reply.started":"2024-05-09T02:56:10.947854Z","shell.execute_reply":"2024-05-09T02:56:10.955806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ncolumn_names = ['Accident_Index', 'Location_Easting_OSGR', 'Location_Northing_OSGR',\n       'Longitude', 'Latitude', 'Police_Force', 'Accident_Severity',\n       'Number_of_Vehicles', 'Number_of_Casualties', 'Date', 'Day_of_Week',\n       'Time', 'Local_Authority_(District)', 'Local_Authority_(Highway)',\n       '1st_Road_Class', '1st_Road_Number', 'Road_Type', 'Speed_limit',\n       'Junction_Detail', 'Junction_Control', '2nd_Road_Class',\n       '2nd_Road_Number', 'Pedestrian_Crossing-Human_Control',\n       'Pedestrian_Crossing-Physical_Facilities', 'Light_Conditions',\n       'Weather_Conditions', 'Road_Surface_Conditions',\n       'Special_Conditions_at_Site', 'Carriageway_Hazards',\n       'Urban_or_Rural_Area', 'Did_Police_Officer_Attend_Scene_of_Accident',\n       'LSOA_of_Accident_Location', 'Vehicle_Reference_x',\n       'Casualty_Reference', 'Casualty_Class', 'Sex_of_Casualty',\n       'Age_of_Casualty', 'Age_Band_of_Casualty', 'Casualty_Severity',\n       'Pedestrian_Location', 'Pedestrian_Movement', 'Car_Passenger',\n       'Bus_or_Coach_Passenger', 'Pedestrian_Road_Maintenance_Worker',\n       'Casualty_Type', 'Casualty_Home_Area_Type', 'Vehicle_Reference_y',\n       'Vehicle_Type', 'Towing_and_Articulation', 'Vehicle_Manoeuvre',\n       'Vehicle_Location-Restricted_Lane', 'Junction_Location',\n       'Skidding_and_Overturning', 'Hit_Object_in_Carriageway',\n       'Vehicle_Leaving_Carriageway', 'Hit_Object_off_Carriageway',\n       '1st_Point_of_Impact', 'Was_Vehicle_Left_Hand_Drive?',\n       'Journey_Purpose_of_Driver', 'Sex_of_Driver', 'Age_of_Driver',\n       'Age_Band_of_Driver', 'Engine_Capacity_(CC)', 'Propulsion_Code',\n       'Age_of_Vehicle', 'Driver_IMD_Decile', 'Driver_Home_Area_Type']\n\n# Convert the list to a pandas Series\ncolumn_series = pd.Series(column_names)\n\n# Check for duplicates\nduplicates = column_series[column_series.duplicated()]\nif not duplicates.empty:\n    print(\"Duplicated column names:\")\n    print(duplicates)\nelse:\n    print(\"No duplicated column names found.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:10.958325Z","iopub.execute_input":"2024-05-09T02:56:10.95865Z","iopub.status.idle":"2024-05-09T02:56:10.976475Z","shell.execute_reply.started":"2024-05-09T02:56:10.958615Z","shell.execute_reply":"2024-05-09T02:56:10.975349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = final_data.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:10.978122Z","iopub.execute_input":"2024-05-09T02:56:10.978452Z","iopub.status.idle":"2024-05-09T02:56:13.531142Z","shell.execute_reply.started":"2024-05-09T02:56:10.978424Z","shell.execute_reply":"2024-05-09T02:56:13.529939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:13.532445Z","iopub.execute_input":"2024-05-09T02:56:13.532834Z","iopub.status.idle":"2024-05-09T02:56:13.55758Z","shell.execute_reply.started":"2024-05-09T02:56:13.532803Z","shell.execute_reply":"2024-05-09T02:56:13.556333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install xlrd\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:13.559265Z","iopub.execute_input":"2024-05-09T02:56:13.560042Z","iopub.status.idle":"2024-05-09T02:56:29.961673Z","shell.execute_reply.started":"2024-05-09T02:56:13.559999Z","shell.execute_reply":"2024-05-09T02:56:29.960425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns.duplicated()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:29.963666Z","iopub.execute_input":"2024-05-09T02:56:29.964134Z","iopub.status.idle":"2024-05-09T02:56:29.973679Z","shell.execute_reply.started":"2024-05-09T02:56:29.964093Z","shell.execute_reply":"2024-05-09T02:56:29.972489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Read the Excel file and sheet\n# casualty_severity = pd.read_excel(\"/kaggle/input/uk-accidents-10-years-history-with-many-variables/Road-Accident-Safety-Data-Guide.xls\", sheet_name=\"Accident Severity\")\n\n# # Perform left join\n# df = pd.merge(df, casualty_severity, left_on=\"Casualty_Severity\", right_on=\"code\", how=\"left\")\n\n# # Rename the column\n# df.rename(columns={\"label\": \"Casualty_Outcome\"}, inplace=True)\n\n# # Optionally, remove the temporary variable\n# del casualty_severity\n\n# Read the Excel file and sheet\ncasualty_severity = pd.read_excel(\"/kaggle/input/uk-accidents-10-years-history-with-many-variables/Road-Accident-Safety-Data-Guide.xls\", sheet_name=\"Accident Severity\")\n\n# Perform left join\ndf = pd.merge(df, casualty_severity, left_on=\"Casualty_Severity\", right_on=\"code\", how=\"left\")\n\n# Rename the column\ndf.rename(columns={\"label\": \"Casualty_Outcome\"}, inplace=True)\n\n# Optionally, remove the temporary variable\ndel casualty_severity","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:29.975281Z","iopub.execute_input":"2024-05-09T02:56:29.975715Z","iopub.status.idle":"2024-05-09T02:56:31.552531Z","shell.execute_reply.started":"2024-05-09T02:56:29.975679Z","shell.execute_reply":"2024-05-09T02:56:31.551398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the Excel file and sheet\nlocation_code = pd.read_excel(\"/kaggle/input/uk-accidents-10-years-history-with-many-variables/Road-Accident-Safety-Data-Guide.xls\", sheet_name=\"Police Force\")\n\n# Perform left join\ndf = pd.merge(df, location_code, left_on=\"Police_Force\", right_on=\"code\", how=\"left\")\n\n# Rename the column\ndf.rename(columns={\"label\": \"Location\"}, inplace=True)\n\n# Optionally, remove the temporary variable\ndel location_code\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:31.553907Z","iopub.execute_input":"2024-05-09T02:56:31.554247Z","iopub.status.idle":"2024-05-09T02:56:36.00482Z","shell.execute_reply.started":"2024-05-09T02:56:31.554219Z","shell.execute_reply":"2024-05-09T02:56:36.003126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the Excel file and sheet\njunction_type = pd.read_excel(\"/kaggle/input/uk-accidents-10-years-history-with-many-variables/Road-Accident-Safety-Data-Guide.xls\", sheet_name=\"Junction Detail\")\n\n# Perform left join\ndf = pd.merge(df, junction_type, left_on=\"Junction_Detail\", right_on=\"code\", how=\"left\")\n\n# Rename the column\ndf.rename(columns={\"label\": \"Junction\"}, inplace=True)\n\n# Optionally, remove the temporary variable\ndel junction_type\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:36.006318Z","iopub.execute_input":"2024-05-09T02:56:36.006709Z","iopub.status.idle":"2024-05-09T02:56:40.247574Z","shell.execute_reply.started":"2024-05-09T02:56:36.006679Z","shell.execute_reply":"2024-05-09T02:56:40.246343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the Excel file and sheet\nlight_conditions = pd.read_excel(\"/kaggle/input/uk-accidents-10-years-history-with-many-variables/Road-Accident-Safety-Data-Guide.xls\", sheet_name=\"Light Conditions\")\n\n# Perform left join with specified suffixes\ndf = pd.merge(df, light_conditions, left_on=\"Light_Conditions\", right_on=\"code\", how=\"left\", suffixes=('_main', '_light'))\n\n# Rename the column\ndf.rename(columns={\"label_light\": \"Lighting\"}, inplace=True)\n\n# Optionally, remove the temporary variable\ndel light_conditions\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:40.249172Z","iopub.execute_input":"2024-05-09T02:56:40.249547Z","iopub.status.idle":"2024-05-09T02:56:44.836415Z","shell.execute_reply.started":"2024-05-09T02:56:40.2495Z","shell.execute_reply":"2024-05-09T02:56:44.835439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the weather conditions data\nweather_conditions = pd.read_excel(\"/kaggle/input/uk-accidents-10-years-history-with-many-variables/Road-Accident-Safety-Data-Guide.xls\", sheet_name=\"Weather\")\n\n# Perform left join to map weather condition codes to labels\ndf = pd.merge(df, weather_conditions, left_on=\"Weather_Conditions\", right_on=\"code\", how=\"left\")\n\n# Rename the column\ndf.rename(columns={\"label\": \"Weather\"}, inplace=True)\n\n# Optionally, remove the temporary variable\ndel weather_conditions\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:44.837702Z","iopub.execute_input":"2024-05-09T02:56:44.838054Z","iopub.status.idle":"2024-05-09T02:56:49.560044Z","shell.execute_reply.started":"2024-05-09T02:56:44.838025Z","shell.execute_reply":"2024-05-09T02:56:49.558959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the surface conditions data\nsurface_conditions = pd.read_excel(\"/kaggle/input/uk-accidents-10-years-history-with-many-variables/Road-Accident-Safety-Data-Guide.xls\", sheet_name=\"Road Surface\")\n\n# Perform left join to map road surface condition codes to labels\ndf = pd.merge(df, surface_conditions, left_on=\"Road_Surface_Conditions\", right_on=\"code\", how=\"left\", suffixes=('_left', '_right'))\n\n# Rename the column\ndf.rename(columns={\"label\": \"Surface\"}, inplace=True)\n\n# Optionally, remove the temporary variable\ndel surface_conditions\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:49.561297Z","iopub.execute_input":"2024-05-09T02:56:49.561584Z","iopub.status.idle":"2024-05-09T02:56:54.547635Z","shell.execute_reply.started":"2024-05-09T02:56:49.56156Z","shell.execute_reply":"2024-05-09T02:56:54.546696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vehicle_type = pd.read_excel(\"/kaggle/input/uk-accidents-10-years-history-with-many-variables/Road-Accident-Safety-Data-Guide.xls\", sheet_name=\"Vehicle Type\")\n\n# Perform left join to map vehicle type codes to labels\ndf = pd.merge(df, vehicle_type, left_on=\"Vehicle_Type\", right_on=\"code\", how=\"left\")\n\n# Rename the column\ndf.rename(columns={\"label\": \"Vehicle\"}, inplace=True)\n\n# Optionally, remove the temporary variable\ndel vehicle_type","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:54.548839Z","iopub.execute_input":"2024-05-09T02:56:54.549134Z","iopub.status.idle":"2024-05-09T02:56:59.748836Z","shell.execute_reply.started":"2024-05-09T02:56:54.549108Z","shell.execute_reply":"2024-05-09T02:56:59.747686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if df contains any columns named \"code\" or \"label\"\nif \"code\" in df.columns or \"label\" in df.columns:\n    # If so, rename or drop these columns\n    df.rename(columns={\"code\": \"code_df\", \"label\": \"label_df\"}, inplace=True)\n    # Or you can drop them if they are not needed\n    # df.drop(columns=[\"code\", \"label\"], inplace=True)\n\n# Read the vehicle manoeuvre data\nvehicle_manoeuvre = pd.read_excel(\"/kaggle/input/uk-accidents-10-years-history-with-many-variables/Road-Accident-Safety-Data-Guide.xls\", sheet_name=\"Vehicle Manoeuvre\")\n\n# Perform left join to map vehicle manoeuvre codes to labels\ndf = pd.merge(df, vehicle_manoeuvre, left_on=\"Vehicle_Manoeuvre\", right_on=\"code\", how=\"left\")\n\n# Rename the column\ndf.rename(columns={\"label\": \"Manoeuvre\"}, inplace=True)\n\n# Optionally, remove the temporary variable\ndel vehicle_manoeuvre\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:56:59.750168Z","iopub.execute_input":"2024-05-09T02:56:59.75049Z","iopub.status.idle":"2024-05-09T02:57:05.303182Z","shell.execute_reply.started":"2024-05-09T02:56:59.750463Z","shell.execute_reply":"2024-05-09T02:57:05.302063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if df contains any columns named \"code\" or \"label\"\nif \"code\" in df.columns or \"label\" in df.columns:\n    # If so, rename or drop these columns\n    df.rename(columns={\"code\": \"code_df\", \"label\": \"label_df\"}, inplace=True)\n    # Or you can drop them if they are not needed\n    # df.drop(columns=[\"code\", \"label\"], inplace=True)\n\n# Read the skidding data\nskidding = pd.read_excel(\"/kaggle/input/uk-accidents-10-years-history-with-many-variables/Road-Accident-Safety-Data-Guide.xls\", sheet_name=\"Skidding and Overturning\")\n\n# Perform left join to map skidding codes to labels\ndf = pd.merge(df, skidding, left_on=\"Skidding_and_Overturning\", right_on=\"code\", how=\"left\")\n\n# Rename the column\ndf.rename(columns={\"label\": \"Skidding\"}, inplace=True)\n\n# Optionally, remove the temporary variable\ndel skidding\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:57:05.304565Z","iopub.execute_input":"2024-05-09T02:57:05.304918Z","iopub.status.idle":"2024-05-09T02:57:11.005852Z","shell.execute_reply.started":"2024-05-09T02:57:05.304891Z","shell.execute_reply":"2024-05-09T02:57:11.0048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if df contains any columns named \"code\" or \"label\"\nif \"code\" in df.columns or \"label\" in df.columns:\n    # If so, rename or drop these columns\n    df.rename(columns={\"code\": \"code_df\", \"label\": \"label_df\"}, inplace=True)\n    # Or you can drop them if they are not needed\n    # df.drop(columns=[\"code\", \"label\"], inplace=True)\n\n# Read the journey purpose data\njourney_purpose = pd.read_excel(\"/kaggle/input/uk-accidents-10-years-history-with-many-variables/Road-Accident-Safety-Data-Guide.xls\", sheet_name=\"Journey Purpose\")\n\n# Perform left join to map journey purpose codes to labels\ndf = pd.merge(df, journey_purpose, left_on=\"Journey_Purpose_of_Driver\", right_on=\"code\", how=\"left\")\n\n# Rename the column\ndf.rename(columns={\"label\": \"Journey\"}, inplace=True)\n\n# Optionally, remove the temporary variable\ndel journey_purpose\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:57:11.014868Z","iopub.execute_input":"2024-05-09T02:57:11.015238Z","iopub.status.idle":"2024-05-09T02:57:17.030983Z","shell.execute_reply.started":"2024-05-09T02:57:11.015208Z","shell.execute_reply":"2024-05-09T02:57:17.029848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if df contains any columns named \"code\" or \"label\"\nif \"code\" in df.columns or \"label\" in df.columns:\n    # If so, rename or drop these columns\n    df.rename(columns={\"code\": \"code_df\", \"label\": \"label_df\"}, inplace=True)\n    # Or you can drop them if they are not needed\n    # df.drop(columns=[\"code\", \"label\"], inplace=True)\n\n# Read the age band data\nage_band = pd.read_excel(\"/kaggle/input/uk-accidents-10-years-history-with-many-variables/Road-Accident-Safety-Data-Guide.xls\", sheet_name=\"Age Band\")\n\n# Perform left join to map age band codes to labels\ndf = pd.merge(df, age_band, left_on=\"Age_Band_of_Driver\", right_on=\"code\", how=\"left\")\n\n# Rename the column\ndf.rename(columns={\"label\": \"Age_Band\"}, inplace=True)\n\n# Optionally, remove the temporary variable\ndel age_band\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:57:17.032238Z","iopub.execute_input":"2024-05-09T02:57:17.032558Z","iopub.status.idle":"2024-05-09T02:57:23.219379Z","shell.execute_reply.started":"2024-05-09T02:57:17.032531Z","shell.execute_reply":"2024-05-09T02:57:23.218316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:57:23.222631Z","iopub.execute_input":"2024-05-09T02:57:23.223095Z","iopub.status.idle":"2024-05-09T02:57:23.251431Z","shell.execute_reply.started":"2024-05-09T02:57:23.223056Z","shell.execute_reply":"2024-05-09T02:57:23.250062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_with_minus_one = df.columns[(df == -1).any()].tolist()\n\nprint(\"Columns containing -1:\")\nprint(columns_with_minus_one)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:57:23.253067Z","iopub.execute_input":"2024-05-09T02:57:23.253482Z","iopub.status.idle":"2024-05-09T02:57:35.323599Z","shell.execute_reply.started":"2024-05-09T02:57:23.253449Z","shell.execute_reply":"2024-05-09T02:57:35.322456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Casualty_Outcome']","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:57:35.324873Z","iopub.execute_input":"2024-05-09T02:57:35.326769Z","iopub.status.idle":"2024-05-09T02:57:35.337097Z","shell.execute_reply.started":"2024-05-09T02:57:35.326724Z","shell.execute_reply":"2024-05-09T02:57:35.334766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat_copy = df.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:57:35.339413Z","iopub.execute_input":"2024-05-09T02:57:35.339899Z","iopub.status.idle":"2024-05-09T02:57:41.128493Z","shell.execute_reply.started":"2024-05-09T02:57:35.33986Z","shell.execute_reply":"2024-05-09T02:57:41.127597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Eliminating extra variables**","metadata":{}},{"cell_type":"code","source":"# Drop specified columns from the DataFrame\ncolumns_to_drop = [\"Driver_Home_Area_Type\", \"Driver_IMD_Decile\", \"Propulsion_Code\", \"Age_Band_of_Driver\", \n                   \"1st_Point_of_Impact\", \"Hit_Object_off_Carriageway\", \"Vehicle_Leaving_Carriageway\", \n                   \"Hit_Object_in_Carriageway\", \"Junction_Location\", \"Vehicle_Location-Restricted_Lane\", \n                   \"Towing_and_Articulation\", \"Pedestrian_Road_Maintenance_Worker\", \"Pedestrian_Movement\", \n                   \"Pedestrian_Location\", \"Casualty_Reference\", \"LSOA_of_Accident_Location\", \n                   \"Did_Police_Officer_Attend_Scene_of_Accident\", \"Urban_or_Rural_Area\", \"Carriageway_Hazards\", \n                   \"Pedestrian_Crossing-Physical_Facilities\", \"Pedestrian_Crossing-Human_Control\", \n                   \"2nd_Road_Class\", \"2nd_Road_Number\", \"Junction_Control\", \"Junction_Detail\", \n                   \"Local_Authority_(Highway)\"]\n\naccidents_data_cleanup = ['Longitude','Time','Speed_limit', 'Junction_Detail', 'Light_Conditions', 'Road_Type',\n                          'Did_Police_Officer_Attend_Scene_of_Accident','Weather_Conditions', \n                          'Road_Surface_Conditions', 'Special_Conditions_at_Site','Carriageway_Hazards', \n                          'Urban_or_Rural_Area', 'Accident_Severity', '1st_Road_Class', \n                          'Pedestrian_Crossing-Human_Control', \n                          'Pedestrian_Crossing-Physical_Facilities', \n                          'Police_Force','Vehicle_Type', 'Sex_of_Driver', 'Age_of_Driver', \n                          'Vehicle_Manoeuvre']\n\ndf_cat_copy = df_cat_copy.drop(columns=columns_to_drop)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:57:41.129873Z","iopub.execute_input":"2024-05-09T02:57:41.130255Z","iopub.status.idle":"2024-05-09T02:57:42.72735Z","shell.execute_reply.started":"2024-05-09T02:57:41.13022Z","shell.execute_reply":"2024-05-09T02:57:42.726274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_to_drop = ['code','code_df']\n\ndf_cat_copy = df_cat_copy.drop(columns=columns_to_drop)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:57:42.728861Z","iopub.execute_input":"2024-05-09T02:57:42.729776Z","iopub.status.idle":"2024-05-09T02:57:44.19448Z","shell.execute_reply.started":"2024-05-09T02:57:42.729709Z","shell.execute_reply":"2024-05-09T02:57:44.193227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_to_drop = ['code_x','code_y','code_main','code_light','code_left','code_right']\n\ndf_cat_copy = df_cat_copy.drop(columns=columns_to_drop)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:57:44.196019Z","iopub.execute_input":"2024-05-09T02:57:44.196431Z","iopub.status.idle":"2024-05-09T02:57:45.625347Z","shell.execute_reply.started":"2024-05-09T02:57:44.196394Z","shell.execute_reply":"2024-05-09T02:57:45.624167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat_copy.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:57:45.626951Z","iopub.execute_input":"2024-05-09T02:57:45.627388Z","iopub.status.idle":"2024-05-09T02:57:45.653645Z","shell.execute_reply.started":"2024-05-09T02:57:45.627347Z","shell.execute_reply":"2024-05-09T02:57:45.65233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_with_minus_one = df_cat_copy.columns[(df_cat_copy == -1).any()].tolist()\n\nprint(\"Columns containing -1:\")\nprint(columns_with_minus_one)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:57:45.655263Z","iopub.execute_input":"2024-05-09T02:57:45.655623Z","iopub.status.idle":"2024-05-09T02:57:56.06908Z","shell.execute_reply.started":"2024-05-09T02:57:45.655585Z","shell.execute_reply":"2024-05-09T02:57:56.067792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat_copy.replace(-1, 'NaN', inplace=True)\ndf_cat_copy.replace(-1, 'NaN', inplace=True)\ndf_cat_copy.replace(-1, 'NaN', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:57:56.071067Z","iopub.execute_input":"2024-05-09T02:57:56.071396Z","iopub.status.idle":"2024-05-09T02:58:57.550916Z","shell.execute_reply.started":"2024-05-09T02:57:56.071368Z","shell.execute_reply":"2024-05-09T02:58:57.549667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_with_minus_one = df_cat_copy.columns[(df_cat_copy == -1).any()].tolist()\n\nprint(\"Columns containing -1:\")\nprint(columns_with_minus_one)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:58:57.552586Z","iopub.execute_input":"2024-05-09T02:58:57.553036Z","iopub.status.idle":"2024-05-09T02:59:22.705419Z","shell.execute_reply.started":"2024-05-09T02:58:57.552997Z","shell.execute_reply":"2024-05-09T02:59:22.704319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat_copy.columns","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:59:22.707365Z","iopub.execute_input":"2024-05-09T02:59:22.707711Z","iopub.status.idle":"2024-05-09T02:59:22.715988Z","shell.execute_reply.started":"2024-05-09T02:59:22.707682Z","shell.execute_reply":"2024-05-09T02:59:22.714913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat_copy.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:59:22.717396Z","iopub.execute_input":"2024-05-09T02:59:22.71784Z","iopub.status.idle":"2024-05-09T02:59:22.746527Z","shell.execute_reply.started":"2024-05-09T02:59:22.717801Z","shell.execute_reply":"2024-05-09T02:59:22.745284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat_copy['Weather_Conditions']","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:59:22.748387Z","iopub.execute_input":"2024-05-09T02:59:22.748926Z","iopub.status.idle":"2024-05-09T02:59:22.762036Z","shell.execute_reply.started":"2024-05-09T02:59:22.748887Z","shell.execute_reply":"2024-05-09T02:59:22.760986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_drop =['Journey_Purpose_of_Driver','Skidding_and_Overturning','Vehicle_Manoeuvre','Road_Surface_Conditions','Weather_Conditions','Light_Conditions','Casualty_Severity']\ndf_cat_copy = df_cat_copy.drop(columns=col_drop)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:59:22.763448Z","iopub.execute_input":"2024-05-09T02:59:22.763908Z","iopub.status.idle":"2024-05-09T02:59:25.147413Z","shell.execute_reply.started":"2024-05-09T02:59:22.763871Z","shell.execute_reply":"2024-05-09T02:59:25.146427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_drop =['Vehicle_Type','Police_Force']\ndf_cat_copy = df_cat_copy.drop(columns=col_drop)\ndf_cat_copy.rename(columns={'Location': 'Police_force'}, inplace=True)\ndf_cat_copy.rename(columns={'label_x': 'Light_conditions'}, inplace=True)\ndf_cat_copy.rename(columns={'label_y': 'Weather_conditions'}, inplace=True)\ndf_cat_copy.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:59:25.148965Z","iopub.execute_input":"2024-05-09T02:59:25.149894Z","iopub.status.idle":"2024-05-09T02:59:27.635046Z","shell.execute_reply.started":"2024-05-09T02:59:25.149851Z","shell.execute_reply":"2024-05-09T02:59:27.633893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reducing data rows to 50000","metadata":{}},{"cell_type":"code","source":"\n\n\n# Calculate the number of rows to delete\n#num_rows_to_delete = 3500000\n\n# Randomly select rows to delete\n#rows_to_delete =df_cat_copy.sample(n=num_rows_to_delete, random_state=42)\n\n# Drop the selected rows from the original DataFrame\n#df_cat_copy_subset =df_cat_copy.drop(rows_to_delete.index)\n\n# Now df_subset contains the DataFrame with 500,000 rows after deleting 3.5 million randomly\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:59:27.636233Z","iopub.execute_input":"2024-05-09T02:59:27.636523Z","iopub.status.idle":"2024-05-09T02:59:27.641407Z","shell.execute_reply.started":"2024-05-09T02:59:27.636498Z","shell.execute_reply":"2024-05-09T02:59:27.64042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Cleaning**","metadata":{}},{"cell_type":"markdown","source":"**Dealing with missing values**","metadata":{}},{"cell_type":"code","source":"# Check for missing values in the entire DataFrame\nmissing_values = df_cat_copy.isnull()\n\n# Count the number of missing values in each column\nmissing_counts =df_cat_copy.isnull().sum()\n\n# Calculate the percentage of missing values in each column\nmissing_percentages = (df_cat_copy.isnull().sum() / len(df_cat_copy)) * 100\n\n# Print the results\nprint(\"Missing value counts:\")\nprint(missing_counts)\nprint(\"\\nMissing value percentages:\")\nprint(missing_percentages)\n\n# print(\"\\nMissing values per column:\")\n# print(final_data.isnull().sum())\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:59:27.642543Z","iopub.execute_input":"2024-05-09T02:59:27.642876Z","iopub.status.idle":"2024-05-09T03:00:04.621227Z","shell.execute_reply.started":"2024-05-09T02:59:27.642847Z","shell.execute_reply":"2024-05-09T03:00:04.620128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove rows with missing values\ndf_cat_copy_cleaned = df_cat_copy.dropna()\n\n# Remove columns with missing values\ndf_cat_copy_cleaned = df_cat_copy.dropna(axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:02:36.004898Z","iopub.execute_input":"2024-05-09T03:02:36.005337Z","iopub.status.idle":"2024-05-09T03:03:03.337899Z","shell.execute_reply.started":"2024-05-09T03:02:36.005307Z","shell.execute_reply":"2024-05-09T03:03:03.336693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat_copy_cleaned.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:03:18.440138Z","iopub.execute_input":"2024-05-09T03:03:18.440525Z","iopub.status.idle":"2024-05-09T03:03:29.834218Z","shell.execute_reply.started":"2024-05-09T03:03:18.440496Z","shell.execute_reply":"2024-05-09T03:03:29.833109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Eliminating Duplicates**","metadata":{}},{"cell_type":"code","source":"df_cat_copy_cleaned.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:03:29.83639Z","iopub.execute_input":"2024-05-09T03:03:29.836839Z","iopub.status.idle":"2024-05-09T03:03:29.844994Z","shell.execute_reply.started":"2024-05-09T03:03:29.836802Z","shell.execute_reply":"2024-05-09T03:03:29.843849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for duplicated rows\nduplicated_rows = df_cat_copy_cleaned.duplicated()\n\n# Select rows that are duplicated\nduplicated = df_cat_copy_cleaned[duplicated_rows]\n\n# Print duplicated data\nprint(\"Duplicated rows:\")\nprint(duplicated)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:03:29.846518Z","iopub.execute_input":"2024-05-09T03:03:29.846896Z","iopub.status.idle":"2024-05-09T03:03:48.495221Z","shell.execute_reply.started":"2024-05-09T03:03:29.846858Z","shell.execute_reply":"2024-05-09T03:03:48.494142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop duplicate rows\ndf_cat_copy_cleaned.drop_duplicates(inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:03:48.498141Z","iopub.execute_input":"2024-05-09T03:03:48.498484Z","iopub.status.idle":"2024-05-09T03:04:09.482375Z","shell.execute_reply.started":"2024-05-09T03:03:48.498454Z","shell.execute_reply":"2024-05-09T03:04:09.481035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat_copy_cleaned.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:09.483849Z","iopub.execute_input":"2024-05-09T03:04:09.484198Z","iopub.status.idle":"2024-05-09T03:04:09.491558Z","shell.execute_reply.started":"2024-05-09T03:04:09.48417Z","shell.execute_reply":"2024-05-09T03:04:09.490498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**detect and remove outliers**","metadata":{}},{"cell_type":"code","source":"import cufflinks as cf\nimport plotly.offline as py\nimport plotly.express as px","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:09.492823Z","iopub.execute_input":"2024-05-09T03:04:09.49316Z","iopub.status.idle":"2024-05-09T03:04:09.502021Z","shell.execute_reply.started":"2024-05-09T03:04:09.493132Z","shell.execute_reply":"2024-05-09T03:04:09.500229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up Plotly offline mode\ncf.go_offline()\npy.init_notebook_mode()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:09.50409Z","iopub.execute_input":"2024-05-09T03:04:09.50443Z","iopub.status.idle":"2024-05-09T03:04:09.592606Z","shell.execute_reply.started":"2024-05-09T03:04:09.504401Z","shell.execute_reply":"2024-05-09T03:04:09.590805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert selected columns to numeric type\nnumeric_columns = ['Age_of_Driver', 'Speed_limit', 'Number_of_Vehicles']\ndf_cat_copy_cleaned[numeric_columns] = df_cat_copy_cleaned[numeric_columns].apply(pd.to_numeric, errors='coerce')","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:09.59419Z","iopub.execute_input":"2024-05-09T03:04:09.594783Z","iopub.status.idle":"2024-05-09T03:04:12.424296Z","shell.execute_reply.started":"2024-05-09T03:04:09.594714Z","shell.execute_reply":"2024-05-09T03:04:12.423194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop rows with missing or non-numeric values\ndf_cat_copy_cleaned.dropna(subset=numeric_columns, inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:12.425806Z","iopub.execute_input":"2024-05-09T03:04:12.426149Z","iopub.status.idle":"2024-05-09T03:04:14.802119Z","shell.execute_reply.started":"2024-05-09T03:04:12.426121Z","shell.execute_reply":"2024-05-09T03:04:14.800951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize data distribution using box plots\n#df_cat_copy_cleaned[numeric_columns].iplot(kind='box', title='Box Plot of Variables')","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:14.806163Z","iopub.execute_input":"2024-05-09T03:04:14.80654Z","iopub.status.idle":"2024-05-09T03:04:14.811452Z","shell.execute_reply.started":"2024-05-09T03:04:14.806509Z","shell.execute_reply":"2024-05-09T03:04:14.810272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to detect outliers using IQR method\ndef detect_outliers_iqr(data, variable):\n    Q1 = data[variable].quantile(0.25)\n    Q3 = data[variable].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    outliers = data[(data[variable] < lower_bound) | (data[variable] > upper_bound)]\n    return outliers\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:14.813109Z","iopub.execute_input":"2024-05-09T03:04:14.814033Z","iopub.status.idle":"2024-05-09T03:04:14.82547Z","shell.execute_reply.started":"2024-05-09T03:04:14.813989Z","shell.execute_reply":"2024-05-09T03:04:14.823958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect outliers for each variable of interest\noutliers = pd.DataFrame()\nfor var in numeric_columns:\n    outliers = pd.concat([outliers, detect_outliers_iqr(df_cat_copy_cleaned, var)])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:14.82722Z","iopub.execute_input":"2024-05-09T03:04:14.827582Z","iopub.status.idle":"2024-05-09T03:04:16.735074Z","shell.execute_reply.started":"2024-05-09T03:04:14.827553Z","shell.execute_reply":"2024-05-09T03:04:16.733965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove outliers from the dataset\nclean_data = df_cat_copy_cleaned.drop(outliers.index)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:16.736365Z","iopub.execute_input":"2024-05-09T03:04:16.736719Z","iopub.status.idle":"2024-05-09T03:04:18.50857Z","shell.execute_reply.started":"2024-05-09T03:04:16.736689Z","shell.execute_reply":"2024-05-09T03:04:18.507515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize outliers using scatter plot\nfig = px.scatter(outliers, x='Age_of_Driver', y='Speed_limit', title='Outliers Detected')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:18.509871Z","iopub.execute_input":"2024-05-09T03:04:18.510213Z","iopub.status.idle":"2024-05-09T03:04:20.496327Z","shell.execute_reply.started":"2024-05-09T03:04:18.510183Z","shell.execute_reply":"2024-05-09T03:04:20.494101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**OneHotEncoder**","metadata":{}},{"cell_type":"markdown","source":"**Scaling**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n# Exclude non-numeric columns\nnumeric_cols = df_cat_copy_cleaned.select_dtypes(include=['number']).columns\n\n# Instantiate the MinMaxScaler\nscaler = MinMaxScaler()\n\n# Fit and transform the numeric columns\nscaled_data = scaler.fit_transform(df_cat_copy_cleaned[numeric_cols])\n\n# Convert the scaled data back to a DataFrame\nscaled_df = pd.DataFrame(scaled_data, columns=numeric_cols)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:20.499064Z","iopub.execute_input":"2024-05-09T03:04:20.499845Z","iopub.status.idle":"2024-05-09T03:04:21.846191Z","shell.execute_reply.started":"2024-05-09T03:04:20.499778Z","shell.execute_reply":"2024-05-09T03:04:21.845122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:21.847601Z","iopub.execute_input":"2024-05-09T03:04:21.847996Z","iopub.status.idle":"2024-05-09T03:04:21.869999Z","shell.execute_reply.started":"2024-05-09T03:04:21.847965Z","shell.execute_reply":"2024-05-09T03:04:21.868819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Normalization**","metadata":{}},{"cell_type":"markdown","source":"First OneHotEncoder","metadata":{}},{"cell_type":"code","source":"df_cat_copy_cleaned.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:21.871321Z","iopub.execute_input":"2024-05-09T03:04:21.871641Z","iopub.status.idle":"2024-05-09T03:04:21.893974Z","shell.execute_reply.started":"2024-05-09T03:04:21.871611Z","shell.execute_reply":"2024-05-09T03:04:21.892662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Convert numeric columns to string if they represent categories\n#df_cat_copy_cleaned['Accident_Severity'] = df_cat_copy_cleaned['Accident_Severity'].astype(str)\n#df_cat_copy_cleaned['Day_of_Week'] = df_cat_copy_cleaned['Day_of_Week'].astype(str)\n\n#df_cat_copy_cleaned.fillna()\n\n# Identify categorical columns\n#categorical_cols = df.select_dtypes(include=['object']).columns\n\n# One-hot encode categorical columns\n#encoded_df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n\n# Now encoded_df contains the one-hot encoded DataFrame\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:21.895491Z","iopub.execute_input":"2024-05-09T03:04:21.895886Z","iopub.status.idle":"2024-05-09T03:04:21.904228Z","shell.execute_reply.started":"2024-05-09T03:04:21.895855Z","shell.execute_reply":"2024-05-09T03:04:21.903103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from sklearn.preprocessing import OneHotEncoder\n\n# Instantiate the OneHotEncoder\n#encoder = OneHotEncoder()\n\n# Fit and transform the data\n#encoded_data = encoder.fit_transform(df_cat_copy_cleaned)\n\n# Convert the encoded data back to a DataFrame\n#encoded_df = pd.DataFrame(encoded_data.toarray(), columns=encoder.get_feature_names_out(df_cat_copy_cleaned.columns))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:21.905695Z","iopub.execute_input":"2024-05-09T03:04:21.906069Z","iopub.status.idle":"2024-05-09T03:04:21.922033Z","shell.execute_reply.started":"2024-05-09T03:04:21.906041Z","shell.execute_reply":"2024-05-09T03:04:21.920573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from sklearn.preprocessing import StandardScaler\n\n# Instantiate the StandardScaler\n#scaler = StandardScaler()\n\n# Fit and transform the data\n#normalized_data = scaler.fit_transform(df_cat_copy_cleaned)\n\n# Convert the normalized data back to a DataFrame\n#normalized_df = pd.DataFrame(normalized_data, columns=df_cat_copy_cleaned.columns)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:21.92358Z","iopub.execute_input":"2024-05-09T03:04:21.923959Z","iopub.status.idle":"2024-05-09T03:04:21.934324Z","shell.execute_reply.started":"2024-05-09T03:04:21.92393Z","shell.execute_reply":"2024-05-09T03:04:21.932958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SimpleImputer**","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.impute import SimpleImputer\n\n\n# Identify numeric and non-numeric columns\nnumeric_cols = df_cat_copy_cleaned.select_dtypes(include=['number']).columns\nnon_numeric_cols = df_cat_copy_cleaned.select_dtypes(exclude=['number']).columns\n\n# Impute missing values for numeric columns\nnumeric_imputer = SimpleImputer(strategy='mean')\ndf_numeric_imputed = pd.DataFrame(numeric_imputer.fit_transform(df_cat_copy_cleaned[numeric_cols]), columns=numeric_cols)\n\n# Impute missing values for non-numeric columns\nnon_numeric_imputer = SimpleImputer(strategy='most_frequent')\ndf_non_numeric_imputed = pd.DataFrame(non_numeric_imputer.fit_transform(df_cat_copy_cleaned[non_numeric_cols]), columns=non_numeric_cols)\n\n# Concatenate numeric and non-numeric columns\ndf_imputed = pd.concat([df_numeric_imputed, df_non_numeric_imputed], axis=1)\n\n# Now df_imputed contains your DataFrame with missing values imputed separately for numeric and non-numeric columns\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:21.935958Z","iopub.execute_input":"2024-05-09T03:04:21.936357Z","iopub.status.idle":"2024-05-09T03:04:57.676008Z","shell.execute_reply.started":"2024-05-09T03:04:21.936325Z","shell.execute_reply":"2024-05-09T03:04:57.674754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_imputed.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:57.677588Z","iopub.execute_input":"2024-05-09T03:04:57.678101Z","iopub.status.idle":"2024-05-09T03:04:57.712457Z","shell.execute_reply.started":"2024-05-09T03:04:57.678064Z","shell.execute_reply":"2024-05-09T03:04:57.711213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Arranging the data logically and sequentially**","metadata":{}},{"cell_type":"code","source":"print(df_cat_copy_cleaned.info())","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:37:55.801023Z","iopub.execute_input":"2024-05-09T03:37:55.801649Z","iopub.status.idle":"2024-05-09T03:37:55.805475Z","shell.execute_reply.started":"2024-05-09T03:37:55.801616Z","shell.execute_reply":"2024-05-09T03:37:55.804545Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# The desired column order\ndesired_order = [\n    'Accident_Index',\n    'Date',\n    'Day_of_Week',\n    'Local_Authority_(District)',\n    'Police_force',\n    '1st_Road_Class',\n    '1st_Road_Number',\n    'Road_Type',\n    'Junction',\n    'Surface',\n    'Weather_conditions',\n    'Light_conditions',\n    'Speed_limit',\n    'Special_Conditions_at_Site',\n    'Number_of_Vehicles',\n    'Vehicle_Reference_x',\n    'Vehicle',\n    'Was_Vehicle_Left_Hand_Drive?',\n    'Vehicle_Reference_y',\n    'Sex_of_Driver',\n    'Age_of_Driver',\n    'Age_Band',\n    'Number_of_Casualties',\n    'Casualty_Class',\n    'Sex_of_Casualty',\n    'Age_of_Casualty',\n    'Age_Band_of_Casualty',\n    'Casualty_Type',\n    'Casualty_Home_Area_Type',\n    'Car_Passenger',\n    'Bus_or_Coach_Passenger',\n    'Casualty_Outcome',\n    'Engine_Capacity_(CC)',\n    'Age_of_Vehicle',\n    'Manoeuvre',\n    'Journey',\n    'Accident_Severity'\n]\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rearrange the columns in the DataFrame\ndf_cat_copy_cleaned = df_cat_copy_cleaned[desired_order]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_cat_copy_cleaned.info())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Grouping Data**","metadata":{}},{"cell_type":"code","source":"# Grouping data horizontally (columns)\nvehicle_info_cols = ['Vehicle_Reference_x', 'Vehicle_Reference_y', 'Vehicle', 'Was_Vehicle_Left_Hand_Drive?', \n                     'Age_of_Vehicle', 'Engine_Capacity_(CC)']\ndriver_info_cols = ['Sex_of_Driver', 'Age_of_Driver']\ncasualty_info_cols = ['Casualty_Class', 'Sex_of_Casualty', 'Age_of_Casualty', 'Age_Band_of_Casualty', \n                      'Casualty_Type', 'Casualty_Home_Area_Type', 'Casualty_Outcome']\nroad_info_cols = ['Road_Type', '1st_Road_Class', '1st_Road_Number', 'Speed_limit', 'Special_Conditions_at_Site', \n                  'Junction', 'Surface']\nweather_info_cols = ['Weather_conditions', 'Light_conditions']\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Grouping data vertically (rows)\nseverity_groups = df_cat_copy_cleaned.groupby('Accident_Severity')\nday_of_week_groups = df_cat_copy_cleaned.groupby('Day_of_Week')\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example of accessing grouped data\nfor severity, severity_group in severity_groups:\n    print(f\"Accident Severity: {severity}\")\n    print(severity_group.head())  # Example: Print first few rows of each severity group\n    print(\"\\n\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor day, day_group in day_of_week_groups:\n    print(f\"Day of Week: {day}\")\n    print(day_group.head())  # Example: Print first few rows of each day of week group\n    print(\"\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Dealing with inconsistent data entry**","metadata":{}},{"cell_type":"code","source":"# Check for unique values in categorical columns\nunique_values = df_cat_copy_cleaned['Weather_conditions'].unique()\nprint(unique_values)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for unique values in categorical columns\nunique_values = df_cat_copy_cleaned['Police_force'].unique()\nprint(unique_values)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for unique values in categorical columns\nunique_values = df_cat_copy_cleaned['Light_conditions'].unique()\nprint(unique_values)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"فاصل","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat_copy_cleaned.columns","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:57.71413Z","iopub.execute_input":"2024-05-09T03:04:57.714485Z","iopub.status.idle":"2024-05-09T03:04:57.727127Z","shell.execute_reply.started":"2024-05-09T03:04:57.714456Z","shell.execute_reply":"2024-05-09T03:04:57.725947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### -changing some columns to their appropriate type ","metadata":{}},{"cell_type":"code","source":"\n\n\ndf_cat_copy_cleaned['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n\n# Convert 'Age_of_Casualty', 'Age_of_Driver', and 'Age_of_Vehicle' columns to numeric (integer or float)\ndf_cat_copy_cleaned['Age_of_Casualty'] = pd.to_numeric(df_cat_copy_cleaned['Age_of_Casualty'], errors='coerce')\ndf_cat_copy_cleaned['Age_of_Driver'] = pd.to_numeric(df_cat_copy_cleaned['Age_of_Driver'], errors='coerce')\ndf_cat_copy_cleaned['Age_of_Vehicle'] = pd.to_numeric(df_cat_copy_cleaned['Age_of_Vehicle'], errors='coerce')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df_cat_copy_cleaned.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### some visuals","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Select numeric columns for correlation matrix\nnumeric_columns = ['Accident_Severity', 'Number_of_Vehicles', 'Number_of_Casualties','Road_Type', 'Speed_limit', 'Vehicle_Reference_y',]\n\n# Calculate correlation matrix\ncorrelation_matrix = df_cat_copy_cleaned[numeric_columns].corr()\n\n# Plot correlation matrix as a heatmap\nplt.figure(figsize=(12, 10))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\nplt.title('Correlation Matrix Heatmap')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__ to discover the severity of different accidents we could explore the relation between diff columns \n\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef explore_relationship(df, var1, var2):\n    \"\"\"\n    Explore the relationship between two variables in a DataFrame.\n    \n    Parameters:\n        df (DataFrame): The pandas DataFrame containing the variables.\n        var1 (str): The name of the first variable.\n        var2 (str): The name of the second variable.\n    \n    Returns:\n        correlation (float): The correlation coefficient between the two variables.\n    \"\"\"\n    # Calculate correlation coefficient\n    correlation = df[var1].corr(df[var2])\n    \n    # Create a scatter plot\n    plt.figure(figsize=(8, 6))\n    plt.scatter(df[var1], df[var2], alpha=0.1)\n    plt.title(f'Scatter Plot: {var1} vs. {var2}')\n    plt.xlabel(var1)\n    plt.ylabel(var2)\n    plt.grid(True)\n    plt.show()\n    \n    return correlation\n\n# Example usage:\n# correlation = explore_relationship(df, 'Age_of_Driver', 'Number_of_Casualties')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explore_relationship(df_cat_copy_cleaned, \"Number_of_Vehicles\" , \"Number_of_Casualties\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### discovering the trends in the data","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set the figure size\nplt.figure(figsize=(17, 4))\n\n# Create the bar plot\nsns.barplot(x='Speed_limit', y='Age_of_Driver', hue='Sex_of_Driver', data=df_cat_copy_cleaned, ci=None, palette='Set2')\n\n# Add legend outside the plot\nplt.legend(bbox_to_anchor=(1, 1))\n\n# Set title and axis labels\nplt.title('Speed_limit vs Age of Driver')\nplt.xlabel('Speed_limit')\nplt.ylabel('Age of Driver')\n\n# Show the plot\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat_copy_cleaned['Sex_of_Driver'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Frequency table\nfrequency_table = df_cat_copy_cleaned['Day_of_Week'].value_counts()\nprint(\"Frequency Table:\")\nprint(frequency_table)\n\n# Bar chart\nplt.figure(figsize=(8, 6))\nsns.countplot(data=df_cat_copy_cleaned, x='Day_of_Week')\nplt.title('Distribution of Accidents by Severity')\nplt.xlabel('Accident Severity')\nplt.ylabel('Count')\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Frequency table\nfrequency_table = df_cat_copy_cleaned['Accident_Severity'].value_counts()\nprint(\"Frequency Table:\")\nprint(frequency_table)\n\n# Bar chart\nplt.figure(figsize=(8, 6))\nsns.countplot(data=df_cat_copy_cleaned, x='Accident_Severity')\nplt.title('Distribution of Accidents by Severity')\nplt.xlabel('Accident Severity')\nplt.ylabel('Count')\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ncategorical_variable = 'Day_of_Week'\n\ncategories = df_cat_copy_cleaned[categorical_variable].unique()\n\nplt.figure(figsize=(15, 10))\n\nfor i, category in enumerate(categories, start=1):\n    data_category = df_cat_copy_cleaned[df_cat_copy_cleaned[categorical_variable] == category]\n    \n    grouped_data = data_category.groupby(['Date', 'Accident_Severity']).size().unstack()\n    mean_severity = grouped_data.mean(axis=1)\n    std_severity = grouped_data.std(axis=1)\n    \n    plt.subplot(3, 3, i)\n    plt.errorbar(mean_severity.index, mean_severity, yerr=std_severity, label=f'{categorical_variable} {category}')\n    plt.title(f'Severity Trend for {categorical_variable} {category}')\n    plt.xlabel('Date')\n    plt.ylabel('Mean Severity')\n    plt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### According to this visualization there is upward trend in average accident severity from day 1->4\n#### Then decreases in day 5-7\n#### The error bars show some variability in severity around the average for each day. The width of the error bars suggests that the severity might be more variable on certain days of the week compared to others.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd  # Assuming 'Date' needs conversion\n\n# Define the categorical variable with a time component\ncategorical_variable = 'Day_of_Week'\n\n# Get the unique categories of the variable\ncategories = df_cat_copy_cleaned[categorical_variable].unique()\n\n# Create subplots for each severity category\nplt.figure(figsize=(15, 10))  # Adjust figure size as needed\n\nfor i, category in enumerate(categories, start=1):\n    # Filter the data for the current category\n    data_category = df_cat_copy_cleaned[df_cat_copy_cleaned[categorical_variable] == category]\n\n    # Handle missing dates (if necessary)\n    data_category.dropna(subset=['Date'], inplace=True)\n\n    # Convert 'Date' to datetime format (if necessary)\n    data_category['Date'] = pd.to_datetime(data_category['Date'])  # Example conversion\n\n    # Group by date and severity category and calculate count of accidents\n    grouped_data = data_category.groupby(['Date', 'Accident_Severity']).size().unstack()\n\n    # Reindex to ensure all severity categories are present as columns\n    grouped_data = grouped_data.reindex(columns=['Fatal', 'Serious', 'Slight'], fill_value=0)\n\n    # Plot the time series for the current category\n    plt.subplot(3, 3, i)\n    sns.lineplot(data=grouped_data, dashes=False)\n\n    # Adjust date ticks and labels (example)\n    plt.xticks(rotation=45, ha='right')  # Rotate long date labels\n\n    # Consider adjusting y-axis scaling if needed\n\n    plt.title(f'Severity Trend for {categorical_variable} {category}')\n    plt.xlabel('Date')\n    plt.ylabel('Number of Accidents')\n    plt.legend(title='Severity')\n\nplt.suptitle('Accident Severity Trends by Day of Week', fontsize=14)  # Overall figure title (optional)\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:18:42.194591Z","iopub.execute_input":"2024-05-09T02:18:42.195029Z","iopub.status.idle":"2024-05-09T02:18:53.88541Z","shell.execute_reply.started":"2024-05-09T02:18:42.194994Z","shell.execute_reply":"2024-05-09T02:18:53.884189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat_copy['Longitude'] = pd.to_numeric(df_cat_copy['Longitude'], errors='coerce')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:04:57.728451Z","iopub.execute_input":"2024-05-09T03:04:57.728818Z","iopub.status.idle":"2024-05-09T03:04:58.480043Z","shell.execute_reply.started":"2024-05-09T03:04:57.728789Z","shell.execute_reply":"2024-05-09T03:04:58.478464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create 3D scatter plot\nimport plotly.express as px\n\nfig = px.scatter_3d(\n    df_cat_copy,\n    x=\"Longitude\",\n    y=\"Latitude\",\n    z=\"Accident_Severity\",\n    labels={\"lon\": \"longitude\", \"lat\": \"latitude\", \"Accident_Severity\": \"Severity\"},\n    width=600,\n    height=500,\n)\n\n# Refine formatting\nfig.update_traces(\n    marker={\"size\": 4, \"line\": {\"width\": 2, \"color\": \"DarkSlateGrey\"}},\n    selector={\"mode\": \"markers\"},\n)\n\n# Display figure\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:48:03.342687Z","iopub.execute_input":"2024-05-09T02:48:03.343173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat_copy_cleaned[\"Accident_Severity\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.scatter_mapbox(\n    df_cat_copy,  # Our DataFrame\n    lon=\"Longitude\",\n    lat=\"Latitude\",\n    width=600,  # Width of map\n    height=600,  # Height of map\n    color=\"Accident_Severity\",\n    hover_data=[\"Accident_Severity\"],  # Display price when hovering mouse over house\n)\n\nfig.update_layout(mapbox_style=\"open-street-map\")\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:06:17.197685Z","iopub.execute_input":"2024-05-09T03:06:17.198144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat_copy.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:31:28.676051Z","iopub.execute_input":"2024-05-09T02:31:28.678408Z","iopub.status.idle":"2024-05-09T02:31:28.69193Z","shell.execute_reply.started":"2024-05-09T02:31:28.67835Z","shell.execute_reply":"2024-05-09T02:31:28.689974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat_copy[\"Accident_Severity\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d","metadata":{},"execution_count":null,"outputs":[]}]}